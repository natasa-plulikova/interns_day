{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d72d7c9-ecef-4785-b2bd-a0891338bb4b",
   "metadata": {},
   "source": [
    "# AI based resource scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b52af-e9bf-424a-88c6-4ebb0c46dbed",
   "metadata": {},
   "source": [
    "## Case scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e722a7-ff8b-4eee-b733-5e3fd54325fc",
   "metadata": {},
   "source": [
    "You and your team have been assigned to a project. The business idea is to reduce carbon footprint by saving resources. Your initial investigation shows, that majority of applications that are deployed on Cloud have high and low traffic hours, but the resources are set to support the peak times. That means there are hours when the allocated resources to the application are not utilized.\n",
    "\n",
    "You want to develop a model which will allow automatic scaling of these resources. For that purpose, your machine learning model should correctly predict the CPU usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eddf4-4898-4f06-baa8-0eb32d2e7e7f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2a8a1-1ab2-44b3-97ed-ed70c29c7678",
   "metadata": {},
   "source": [
    "The extract of the data for a sample application was provided to you. In the `data` folder you will find 2 files: `train.csv` and `test.csv`. You should conduct your exploration and model building on the `train.csv` file.\n",
    "Once you are happy with the model, use the `test.csv` file to predict the `cpu_usage`. You should store your predictions in a new csv file which will be called `<your_name>.csv`. The new file should have the following attributes:\n",
    "- `id` column\n",
    "- `timestamp` column\n",
    "- `cpu_usage` column which should hold your predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be9c7b-428b-4882-a94f-b65b61a94aff",
   "metadata": {},
   "source": [
    "### Data explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde4c1e-3cf2-4d38-af8a-c08a00bdfbdc",
   "metadata": {},
   "source": [
    "- `id` - identifier of the record\n",
    "- `timestamp` - timestamp in the format YYYY-MM-DD HH-MM-SS\n",
    "- `number_of_requests` - number of requests the application received in the given time\n",
    "- `number_of_errors` - number of errors that the application logged in the given time\n",
    "- `response_time` - cummulative time the application took to respond to a request, in miliseconds\n",
    "- `cpu_cores` - number of CPU cores allocated to the application at a given time (maximum 8 are available)\n",
    "- `memory_usage` - memory allocation in a given time, in percent\n",
    "- `cpu_usage` - cpu allocation in a given time, in percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24110c8e-2eb2-4db1-ba12-d24f6ef5c928",
   "metadata": {},
   "source": [
    "## Your delivery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c9ae1-eda2-4bdb-bfda-dd2e5589a36a",
   "metadata": {},
   "source": [
    "At the end of the day, you should provide us with your code in which you demonstrate that you followed these steps:\n",
    "1. Data load\n",
    "2. Data cleaning\n",
    "3. Data Exploration\n",
    "4. Data Modeling and validation\n",
    "5. Prediction\n",
    "\n",
    "The submission should be done as a pull request (PR) on github to this repository. **Please use branch with your name (not main branch)**. The PR should contain the `<your_name>.csv` file stored in the `data` folder and your code stored either in a jupyter notebook or python module.\n",
    "We have prepared this notebook to help you with the exercise however you are not obliged to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4820fc-2509-4d37-9ed5-65f605fb98cd",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018874d3-b86b-48ad-bd9a-94f129fa35dc",
   "metadata": {},
   "source": [
    "This exercise does not have one solution. The problem can be approached in multiple ways. In order to evaluate how well your model performs, we will use the  root mean squared error (RMSE) metric. You can learn more about this metric here: https://en.wikipedia.org/wiki/Root-mean-square_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b0a26-34bf-41f2-a52d-2199fb74e680",
   "metadata": {},
   "source": [
    "# Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025f5bd-2180-4399-bc55-b0dfec2f99fb",
   "metadata": {},
   "source": [
    "## Getting this to your local environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d95fee-b024-4ce4-859b-6c69ebe688b8",
   "metadata": {},
   "source": [
    "Make sure you have an account at github.com. We suggest you fork this repository to your own space. Refer here to quickly get the right git commands: https://docs.github.com/en/get-started/quickstart/git-cheatsheet or simply use Github Desktop: https://desktop.github.com/.\n",
    "Before you start working, make sure that your work can be reproduced later on a different machine.\n",
    "\n",
    "Hint: define the environment for your project along with all dependencies. Make sure that any random element you use in your code is started from the same seed value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fc3ba",
   "metadata": {},
   "source": [
    "## Git cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a915efa1",
   "metadata": {},
   "source": [
    "If you are familiar with git/github and you know your way around, you can skip this section. \n",
    "\n",
    "### Basic Github Flow\n",
    "Follwing [video](https://ibm.box.com/s/dvym4y5ktbcw8sdv02hecfs5wwe0dn22) describes basic github workflow. It describes how to fork repository, clone it, make some changes, push changes to remote repo and create pull request against original repository. \n",
    "\n",
    "### Cloning repo\n",
    "Before you can clone repo you need either github token or ssh key. If you do not have it setup please follow this [guide](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account)\n",
    "\n",
    "### Usual workflow\n",
    "Your usual worklow might look like this:\n",
    "1. Fork and clone repo on your local (first part of video)\n",
    "2. Develop your solution, periodically commiting changes when you reach some milestone\n",
    "3. Push changes to remote server if you are finished or you want just make copy on remote server just in case :-).\n",
    "4. Once you are done with your solution. Create pull request as show in second part of the video. **Please remember to create pull request against branch with your name (do not use main branch).**\n",
    "\n",
    "### Useful git commands\n",
    "Here are some useful git commands:\n",
    "* ```git clone <repo url>``` - clone repo from remote location to local directory\n",
    "* ```git add <file|folder>``` - stage your changes \n",
    "* ```git commit -m \"commit message\"``` - commit your changes to local git repo\n",
    "* ```git push``` - push changes to remote git repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861b71a-bbb5-41b0-86cb-eca66fd17118",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c2621a0-370c-471a-b5b0-c4b40bd7aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782938b-41f5-4337-b48a-f96f79d1f645",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484af96-1993-4117-8bc6-4e3e6f14f388",
   "metadata": {},
   "source": [
    "In this step you want to make sure that the data that you work with is loaded correctly, that it does not contain any strange values or that you are not missing any important records. You can read more about this step here: https://en.wikipedia.org/wiki/Data_cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7217dd75-c58b-469e-ba89-5c16fc6d9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "df_test = df_test.fillna(0)\n",
    "df_train = df_train.fillna(0) #cleanig datasets from NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e63b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cd37f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().values.any() #check for NaN values after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbfce8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.rename(columns={'Unnamed: 0':'id'}, inplace=True) #add name for missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd1568bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['id'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3231752f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['id'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "421ce3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.set_index('id')\n",
    "df_train =df_train.set_index('id') #setting indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac0b69e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    3\n",
       "int64      2\n",
       "object     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dtypes.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf4d5a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>number_of_requests</th>\n",
       "      <th>number_of_errors</th>\n",
       "      <th>response_time</th>\n",
       "      <th>cpu_cores</th>\n",
       "      <th>memory_usage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51601</th>\n",
       "      <td>2022-01-25 16:52:27</td>\n",
       "      <td>6013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13839.534811</td>\n",
       "      <td>6</td>\n",
       "      <td>0.332282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51602</th>\n",
       "      <td>2022-01-25 16:52:32</td>\n",
       "      <td>8834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14657.609451</td>\n",
       "      <td>6</td>\n",
       "      <td>0.931217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51603</th>\n",
       "      <td>2022-01-25 16:52:37</td>\n",
       "      <td>7971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14137.221618</td>\n",
       "      <td>6</td>\n",
       "      <td>0.803488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51604</th>\n",
       "      <td>2022-01-25 16:52:42</td>\n",
       "      <td>7653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14257.821995</td>\n",
       "      <td>6</td>\n",
       "      <td>0.486343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51605</th>\n",
       "      <td>2022-01-25 16:52:47</td>\n",
       "      <td>7313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14281.586371</td>\n",
       "      <td>6</td>\n",
       "      <td>0.369045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68796</th>\n",
       "      <td>2022-01-26 16:45:22</td>\n",
       "      <td>6401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13977.819765</td>\n",
       "      <td>6</td>\n",
       "      <td>0.863818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68797</th>\n",
       "      <td>2022-01-26 16:45:27</td>\n",
       "      <td>6525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14401.515182</td>\n",
       "      <td>6</td>\n",
       "      <td>0.300279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68798</th>\n",
       "      <td>2022-01-26 16:45:32</td>\n",
       "      <td>8342</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14782.197038</td>\n",
       "      <td>6</td>\n",
       "      <td>0.165270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68799</th>\n",
       "      <td>2022-01-26 16:45:37</td>\n",
       "      <td>5355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14421.113212</td>\n",
       "      <td>6</td>\n",
       "      <td>0.377384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68800</th>\n",
       "      <td>2022-01-26 16:45:42</td>\n",
       "      <td>6476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14714.010527</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  number_of_requests  number_of_errors  \\\n",
       "id                                                                 \n",
       "51601  2022-01-25 16:52:27                6013               1.0   \n",
       "51602  2022-01-25 16:52:32                8834               0.0   \n",
       "51603  2022-01-25 16:52:37                7971               0.0   \n",
       "51604  2022-01-25 16:52:42                7653               0.0   \n",
       "51605  2022-01-25 16:52:47                7313               0.0   \n",
       "...                    ...                 ...               ...   \n",
       "68796  2022-01-26 16:45:22                6401               0.0   \n",
       "68797  2022-01-26 16:45:27                6525               1.0   \n",
       "68798  2022-01-26 16:45:32                8342               2.0   \n",
       "68799  2022-01-26 16:45:37                5355               1.0   \n",
       "68800  2022-01-26 16:45:42                6476               0.0   \n",
       "\n",
       "       response_time  cpu_cores  memory_usage  \n",
       "id                                             \n",
       "51601   13839.534811          6      0.332282  \n",
       "51602   14657.609451          6      0.931217  \n",
       "51603   14137.221618          6      0.803488  \n",
       "51604   14257.821995          6      0.486343  \n",
       "51605   14281.586371          6      0.369045  \n",
       "...              ...        ...           ...  \n",
       "68796   13977.819765          6      0.863818  \n",
       "68797   14401.515182          6      0.300279  \n",
       "68798   14782.197038          6      0.165270  \n",
       "68799   14421.113212          6      0.377384  \n",
       "68800   14714.010527          6      0.714845  \n",
       "\n",
       "[17200 rows x 6 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f660e38-a542-4892-a614-40fe8af4a41f",
   "metadata": {},
   "source": [
    "## 3. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa9061-7e86-4756-a646-7431c9617d77",
   "metadata": {},
   "source": [
    "This may be one of the most important steps in your analysis. Your objective is to explore patterns in the data that will later drive your decisions about the suitable prediction model. You can read more about this step here: https://en.wikipedia.org/wiki/Data_exploration.\n",
    "\n",
    "There are many visualization libraries in python which can help you visualize and better understand the relationships between the data. Some of the most used ones are `matplotlib` (https://matplotlib.org/) and `seaborn` (https://seaborn.pydata.org/)\n",
    "\n",
    "At the end of this step, you should be able to make some important decisions. For example, will you include all features, or only a subset? Will you create new features? How will you treat your target variable? Will you need to encode the data in a different way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff321bec-090c-4b20-8987-8cdf567663fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbf95d-5edb-49e3-85a5-15d3d20e638c",
   "metadata": {},
   "source": [
    "## 4. Data Modeling and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2eb3b8-cb4d-419b-9702-3bd5a623e77a",
   "metadata": {},
   "source": [
    "At this point, you should have an idea about your data. That means you are ready for the modeling part. Based on your exploration, you should choose the right type of the model. Since we are operating in a supervised domain (e.g. we know what we want to predict), your main decision should be whether to use a classification, regression or time-series type model.\n",
    "\n",
    "Scikit-learn (https://scikit-learn.org/stable/index.html) is very broad library for machine learning practitioners. The documentation provides examples for different machine learning problems. Feel free to check it out before you choose your final implementation. If you are not sure which model will work best, you can also train multiple models and choose the best among them.\n",
    "\n",
    "Do not forget that you need to validate your model. Especially if you train multiple models that you wish to choose from. There are more ways to do the validation (read more here: https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets) but remember that your final solution will be evaluated based on RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c56496-a6c5-40a1-9498-b847d40c981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a236ff3-b299-48fe-9f67-a8d4e65dfa59",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b9a3f-b96c-4602-8946-adc9cd096e2c",
   "metadata": {},
   "source": [
    "Well done! You are almost finished with the assignment. In this last step you want to use a `predict` method on the data from `test.csv` file. Remember, any transformation or data preprocessing steps you did need to be done on this dataset too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37a262-2aa6-4686-827d-a18e83d176e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835420e8-fc44-406c-9648-0ac6fb2d7cf7",
   "metadata": {},
   "source": [
    "<div align=\"center\"> Well done! </div>\n",
    "You have completed all the steps necessary for the assignment. Don't forget to submit your solution according to instructions.\n",
    "We hope you have enjoyed this and we thank you for your time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
